{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "Tiny Lego dataset\n",
    "- https://people.eecs.berkeley.edu/~bmild/nerf/tiny_nerf_data.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"tiny_nerf_data.npz\"):\n",
    "  !wget https://people.eecs.berkeley.edu/~bmild/nerf/tiny_nerf_data.npz\n",
    "\n",
    "dataset = np.load(\"tiny_nerf_data.npz\")\n",
    "print(dataset[\"images\"].shape)\n",
    "print(dataset[\"poses\"].shape)\n",
    "print(dataset['focal'])\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(30,4))\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    plt.sca(ax)\n",
    "    plt.imshow(dataset['images'][i])\n",
    "    plt.title('Image: {}'.format(i+1))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading (Pinhole Camera Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = dataset['poses']\n",
    "dirs = np.stack([np.sum([0, 0, -1] * pose[:3, :3], axis=-1) for pose in poses])\n",
    "origins = poses[:, :3, 3]\n",
    "\n",
    "ax = plt.figure(figsize=(12,8)).add_subplot(projection=\"3d\")\n",
    "_ = ax.quiver(\n",
    "    origins[..., 0].flatten(),\n",
    "    origins[..., 1].flatten(),\n",
    "    origins[..., 2].flatten(),\n",
    "    dirs[..., 0].flatten(),\n",
    "    dirs[..., 1].flatten(),\n",
    "    dirs[..., 2].flatten(), length=0.5, normalize=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rays(h: int, w: int, focal_length: float, pose: torch.Tensor):\n",
    "  i, j = torch.meshgrid(\n",
    "      torch.arange(w, dtype=torch.float32).to(pose),\n",
    "      torch.arange(h, dtype=torch.float32).to(pose),\n",
    "      indexing='ij')\n",
    "  i, j = i.transpose(-1, -2), j.transpose(-1, -2)\n",
    "  rays_d = torch.stack([(i - w * .5) / focal_length,\n",
    "                            -(j - h * .5) / focal_length,\n",
    "                            -torch.ones_like(i)\n",
    "                           ], dim=-1)\n",
    "  rays_d = torch.sum(rays_d[..., None, :] * pose[:3, :3], dim=-1)\n",
    "  rays_o = pose[:3, -1].expand(rays_d.shape)\n",
    "  return rays_o, rays_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_sampling(\n",
    "    rays_o,\n",
    "    rays_d,\n",
    "    near,\n",
    "    far,\n",
    "    n,\n",
    "):\n",
    "  # shape: (num_samples)\n",
    "  t = torch.linspace(near, far, n).to(rays_o)\n",
    "  \n",
    "  # ray_origins: (width, height, 3)\n",
    "  # noise_shape = (width, height, num_samples)\n",
    "  noise_shape = list(rays_o.shape[:-1]) + [n]\n",
    "  \n",
    "  # depth_values: (num_samples)\n",
    "  t = t + torch.rand(noise_shape).to(rays_o) * (far - near) / n\n",
    "  \n",
    "  # (width, height, num_samples, 3) = (width, height, 1, 3) + (width, height, 1, 3) * (num_samples, 1)\n",
    "  # query_points:  (width, height, num_samples, 3)\n",
    "  x = rays_o[..., None, :] + rays_d[..., None, :] * t[..., :, None]\n",
    "  \n",
    "  return x, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positional_encoding(\n",
    "    x, L=6, include_input=True\n",
    ") -> torch.Tensor:\n",
    "  encoding = [x] if include_input else []\n",
    "  frequency_bands = 2.0 ** torch.linspace(\n",
    "        0.0,\n",
    "        L - 1,\n",
    "        L,\n",
    "        dtype=x.dtype,\n",
    "        device=x.device,\n",
    "  )\n",
    "  for freq in frequency_bands:\n",
    "    encoding.append(torch.sin(x * freq * np.pi))\n",
    "    encoding.append(torch.cos(x * freq * np.pi))\n",
    "  \n",
    "  return torch.cat(encoding, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO 1.\n",
    "def volume_rendering(c, sigma, rays_o, t):\n",
    "  sigma = torch.nn.functional.relu(sigma)[...,0]\n",
    "  c = torch.sigmoid(c)\n",
    "  delta = t[..., 1:] - t[..., :-1]\n",
    "  delta = torch.cat([delta, torch.tensor([1e10], dtype=rays_o.dtype, device=rays_o.device).expand(t[...,:1].shape)], dim=-1)\n",
    "\n",
    "  alpha = 1. - torch.exp(-sigma * delta)\n",
    "  T = torch.cumprod(1. - alpha + 1e-10, -1)\n",
    "  T = torch.roll(T, 1, -1)\n",
    "  T[..., 0] = 1.\n",
    "\n",
    "  w = T * alpha\n",
    "\n",
    "  rgb = (w[..., None] * c).sum(dim=-2)\n",
    "  return rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeRF(torch.nn.Module):\n",
    "  def __init__(self, gamma_x_dim=60, gamma_d_dim=24, num_channels=256, num_layers=8, skip=4):\n",
    "    super(NeRF, self).__init__()\n",
    "\n",
    "    self.layers = []\n",
    "    for i in range(num_layers):\n",
    "      if i == 0:\n",
    "        self.layers.append(torch.nn.Linear(gamma_x_dim, num_channels))\n",
    "      elif not i == skip:\n",
    "        self.layers.append(torch.nn.Linear(num_channels, num_channels))\n",
    "      else: \n",
    "        self.layers.append(torch.nn.Linear(num_channels + gamma_x_dim, num_channels))\n",
    "    self.layers = torch.nn.ModuleList(self.layers)\n",
    "    self.sigma_out = torch.nn.Linear(num_channels, 1)\n",
    "\n",
    "    self.feature = torch.nn.Linear(num_channels, num_channels)\n",
    "    self.branch = torch.nn.Linear(num_channels + gamma_d_dim, num_channels // 2)\n",
    "    self.rgb_out = torch.nn.Linear(num_channels // 2, 3)\n",
    "\n",
    "    self.skip = skip\n",
    "    self.relu = torch.nn.functional.relu\n",
    "  \n",
    "  def forward(self, x, d):\n",
    "    out = x\n",
    "    for i, l in enumerate(self.layers):\n",
    "      if not i == self.skip:\n",
    "        out = self.relu(self.layers[i](out))\n",
    "      else:\n",
    "        out = torch.concat([out, x], dim=-1)\n",
    "        out = self.relu(self.layers[i](out))\n",
    "\n",
    "    sigma = self.sigma_out(out)\n",
    "\n",
    "    out = self.feature(out)\n",
    "    out = torch.concat([out, d], dim=-1)\n",
    "    out = self.relu(self.branch(out))\n",
    "    color = self.rgb_out(out)\n",
    "\n",
    "    return color, sigma"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
